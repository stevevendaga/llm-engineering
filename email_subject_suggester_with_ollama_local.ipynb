{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8ffb3d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import requests        # For making HTTP requests to check Ollama server status\n",
    "import os            # For environment variable handling (not currently used but may be needed)\n",
    "from openai import OpenAI  # For interfacing with Ollama API using OpenAI-compatible interface\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "24117d68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status Code: 200\n",
      "Response: Ollama is running\n"
     ]
    }
   ],
   "source": [
    "# Check if Ollama is running by making a proper request\n",
    "try:\n",
    "    response = requests.get(\"http://localhost:11434\")\n",
    "    print(f\"Status Code: {response.status_code}\")\n",
    "    print(f\"Response: {response.text}\")\n",
    "except requests.exceptions.ConnectionError:\n",
    "    print(\"Cannot connect to Ollama. Make sure it's running on localhost:11434\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a81a296e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declarations\n",
    "OLLAMA_BASE_URL = \"http://localhost:11434/v1\"  # Ollama API endpoint with OpenAI-compatible interface\n",
    "\n",
    "# Initialize OpenAI client with Ollama as backend\n",
    "ollama = OpenAI(base_url=OLLAMA_BASE_URL, api_key=\"ollama\")\n",
    "\n",
    "model = \"llama3.2\"  # Specify the model to use for generating email subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "80cc9514",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install llama3.2 model from ollama\n",
    "# !ollama pull llama3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f783c6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# System message for the model\n",
    "# Multiple system message options are provided - uncomment the one that best fits your use case\n",
    "# system_message = \"You are a helpful assistant that suggest email subject for a given email body.\"\n",
    "# system_message = \"You are an expert email marketer who specializes in creating compelling, concise, and engaging email subject lines. Your task is to suggest 3-5 different subject line options for the given email body, ensuring they are attention-grabbing, relevant, and encourage opens.\"\n",
    "system_message = \"You are a creative copywriter specializing in email subject lines. Generate 3-5 distinct subject line variations for the provided email content, using different approaches such as: curiosity-driven, benefit-focused, urgent, personal, or question-based hooks.\"\n",
    "# system_message = \"You are an email optimization specialist. For the given email body, create 3-5 high-performing subject line options that maximize open rates by being clear, compelling, and relevant to the content while maintaining brand voice.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f06b5e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declarations\n",
    "OLLAMA_BASE_URL = \"http://localhost:11434/v1\"  # Ollama API endpoint with OpenAI-compatible interface\n",
    "\n",
    "# Initialize OpenAI client with Ollama as backend\n",
    "ollama = OpenAI(base_url=OLLAMA_BASE_URL, api_key=\"ollama\")\n",
    "\n",
    "model = \"llama3.2\"  # Specify the model to use for generating email subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "247303c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# User message - the email body for which we want to generate subject lines\n",
    "user_message = \"Dear Customer, \" \\\n",
    "\"You've hustled through deadlines, traffic, and everything in between \" \\\n",
    "\"You've shown up, built, grown, and probably said God, abeg more times than you can count. \" \\\n",
    "\"You made it this far. And as the year wraps up, you deserve to enjoy it. \" \\\n",
    "\"Whether it's 'Detty December' plans, a quick getaway, or just peace of mind at home, this next chapter is about celebrating wisely. \" \\\n",
    "\"Because heroes don't just fight battles: they protect what they've built. \" \\\n",
    "\"Here's how you can make your 2025 ending (and 2026 beginning) even stronger\"\n",
    "\n",
    "# This is a motivational/financial planning email targeting hardworking individuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e68be662",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the conversation messages in the required format\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": system_message},  # Defines the AI's behavior\n",
    "    {\"role\": \"user\", \"content\": user_message}       # Provides the input email content\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3615f4e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Here are 3-5 subject line variations that incorporate different approaches:\n",
       "\n",
       "**Curiosity-driven approach**\n",
       "1. What's Next for Your Business in 2025?\n",
       "2. The Ultimate Checklist to Conquer 2026\n",
       "\n",
       "**Benefit-focused approach**\n",
       "1. Level Up: Proven Strategies to Supercharge Your Success\n",
       "2. From Stress to Serenity: Celebrate the End of Year in Style\n",
       "\n",
       "**Urgent approach**\n",
       "1. Last Chance to Secure Your 2025 Goals\n",
       "2. Time's Running Out: Create a Winning Legacy for 2026\n",
       "\n",
       "**Personal approach**\n",
       "1. Your Year-End Reflections: How to Write the Next Chapter\n",
       "2. To a Hero, A Hero's Gift: Exclusive Insights from [Your Brand]\n",
       "\n",
       "**Question-based hooks**\n",
       "1. Did You Forget One Thing on Your Path to Success?\n",
       "2. What Would Be the Perfect Way for You to Welcome 2026?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# implementation\n",
    "# Send the request to Ollama and get the response\n",
    "response = ollama.chat.completions.create(model=model, messages=messages)\n",
    "\n",
    "# Print the generated email subject suggestions\n",
    "# print(response.choices[0].message.content)\n",
    "\n",
    "#  Display the response in Markdown\n",
    "response_content = response.choices[0].message.content\n",
    "\n",
    "display(Markdown(response_content))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLM Engineer",
   "language": "python",
   "name": "llm-engineer"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
